{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "add527d1-2e52-4f67-8a98-6e06de83211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34321f38-8983-4630-a452-23934300aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='data',train=True, transform=transform,download=False)\n",
    "test_dataset = datasets.MNIST(root='data',train=False, transform=transform, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256,)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd808da-7b7f-49fc-9209-37498cea2e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    print(labels[:10])\n",
    "    break\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19b970-cf75-46d7-97f3-ef3b00644ef3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "630899e6-24ca-400a-a521-e8b52a38ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom reshape class\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super(Reshape,self).__init__()\n",
    "        self.shape = args\n",
    "    def forward(self,x):\n",
    "        with_new_shape = x.view(self.shape)\n",
    "        return with_new_shape\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super(Trim, self).__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x[:, :, :28, :28]\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(32,64,3,stride=2,padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(64,64, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(64,64, 3, stride=1, padding=1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.z_mean = torch.nn.Linear(3136,2)\n",
    "        self.z_log_var = torch.nn.Linear(3136,2)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,3136),\n",
    "            Reshape(-1,64,7,7),\n",
    "            nn.ConvTranspose2d(64,64, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(64,64,3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(64,32,3, stride=2, padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(32,1,3 ,stride=1, padding=0),\n",
    "            Trim(),\n",
    "            nn.Sigmoid()\n",
    "                               \n",
    "            \n",
    "        )\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        eps = torch.randn(mean.size(0),mean.size(1))\n",
    "        sigma = torch.exp(log_var/2.0)\n",
    "        z = mean+sigma*eps\n",
    "        return z\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=  x.view((-1,1,28,28))\n",
    "        encoded=self.encoder(x)\n",
    "        mean = self.z_mean(encoded)\n",
    "        log_variance = self.z_log_var(encoded)\n",
    "        encoded_z  = self.reparameterize(mean, log_variance)\n",
    "        decoded=self.decoder(encoded_z)\n",
    "        return encoded, mean, log_variance, decoded\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ecc37475-c8f5-4d79-8912-fdfde10ff57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate VAE\n",
    "torch.manual_seed(2342)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model=VAE()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d0e05b82-0724-4df6-9326-3d716b1cd75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(225.3925, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,mean, log_var, reconstruction = model(images)\n",
    "loss_fn = F.mse_loss\n",
    "reconstruction_loss = loss_fn(reconstruction, images, reduction='none')\n",
    "kl_loss=torch.sum(-0.5*(1+log_var - mean**2 - torch.exp(log_var)),axis=1)\n",
    "batch_size=kl_loss.size(0\n",
    "                       )\n",
    "kl_loss_avg = kl_loss.mean()\n",
    "reconstruction_loss= reconstruction_loss.view(batch_size,-1).sum(axis=1)\n",
    "reconstruction_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b5011-cb5d-43e7-9031-7d3e94959106",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa99d1df-7fa3-465b-a3ea-fa2737b0de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epoch_loss_autoencoder(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    curr_loss, num_examples = 0., 0\n",
    "    with torch.no_grad():\n",
    "        for features, _ in data_loader:\n",
    "            features = features.to(device)\n",
    "            logits = model(features)\n",
    "            loss = loss_fn(logits, features, reduction='sum')\n",
    "            num_examples += features.size(0)\n",
    "            curr_loss += loss\n",
    "\n",
    "        curr_loss = curr_loss / num_examples\n",
    "        return curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9806d036-4231-498d-b8d4-872c5e221219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "log_dict = {'train_combined_loss_per_epoch': [],\n",
    "           'train_combine_loss_per_batch':[],\n",
    "           'train_reconstruction_loss_per_batch':[],\n",
    "           'train_kl_loss_per_batch':[]}\n",
    "loss_fn = F.mse_loss\n",
    "start_time = time.time()\n",
    "def train_vae(num_epochs, model, optimizr, device, train_loader,\n",
    "             loss_fn=None,\n",
    "             logging_interval=100,\n",
    "             skip_epoch_stats=False,\n",
    "             reconstruction_term_weight=1,\n",
    "             save_model=None)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (features, _) in enumerate(train_loader):\n",
    "            feautres = features.to(device)\n",
    "             _, mean, log_var, reconstruction=model(features)\n",
    "    \n",
    "            # KL Div Loss\n",
    "            kl_loss=torch.sum(-0.5*(1+log_var - mean**2 - torch.exp(log_var)),axis=1)\n",
    "            batch_size=kl_loss.size(0)\n",
    "                        \n",
    "            kl_loss_avg = kl_loss.mean()\n",
    "             ## Reconstruction Loss\n",
    "            reconstruction_loss = loss_fn(reconstruction, images,reduction='none')\n",
    "            reconstruction_loss = reconstruction_loss.view(batch_size, -1).sum(axis=1)\n",
    "            reconstruction_loss=reconstruction_loss.mean()\n",
    "            \n",
    "            total_loss = reconstruction_loss+kl_loss_avg\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # LOGGING\n",
    "            log_dict['train_combined_loss_per_batch'].append(loss.item())\n",
    "            log_dict['train_reconstruction_loss_per_batch'].append(pixelwise.item())\n",
    "            log_dict['train_kl_loss_per_batch'].append(kl_div.item())\n",
    "            \n",
    "            if not batch_idx % logging_interval:\n",
    "                print('Epoch: %03d/%03d | Batch %04d/%04d | Loss: %.4f'\n",
    "                          % (epoch+1, num_epochs, batch_idx,\n",
    "                              len(train_loader), loss))\n",
    "        if not skip_epoch_stats:\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.set_grad_enabled(False):  # save memory during inference\n",
    "                    \n",
    "                    train_loss = compute_epoch_loss_autoencoder(\n",
    "                        model, train_loader, loss_fn, device)\n",
    "                    print('***Epoch: %03d/%03d | Loss: %.3f' % (\n",
    "                          epoch+1, num_epochs, train_loss))\n",
    "                    log_dict['train_combined_per_epoch'].append(train_loss.item())\n",
    "        print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "    print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "    if save_model is not None:\n",
    "        torch.save(model.state_dict(), save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f128837-2bf0-47b7-affb-718e104ca3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
